#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•è¯è®°å¿†ç¨‹åº - æ ¸å¿ƒæ¨¡å— (é‡æ„ç‰ˆæœ¬)
æŠ½è±¡åŒ–æ¥å£è®¾è®¡ï¼Œæ”¯æŒå¤šç§UIå®ç°
"""

import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Protocol, Callable, Tuple
from dataclasses import dataclass, asdict, field
from enum import Enum
from abc import ABC, abstractmethod
import uuid
import threading
import time
import operator

from utils import enum_asdict


class WordStatus(Enum):
    DRAFT = "draft"
    LEARNING = "learning" 
    REVIEWING = "reviewing"
    MASTERED = "mastered"


class DifficultyLevel(Enum):
    EASY = 1
    MEDIUM = 2
    HARD = 3
    VERY_HARD = 4


class SortOrder(Enum):
    """æ’åºæ–¹å¼"""
    ALPHABETICAL = "alphabetical"  # æŒ‰å­—æ¯é¡ºåº
    ADDED_TIME = "added_time"      # æŒ‰æ·»åŠ æ—¶é—´
    REVIEW_TIME = "review_time"    # æŒ‰å¤ä¹ æ—¶é—´
    COMPLETENESS = "completeness"  # æŒ‰å®Œæ•´åº¦
    STATUS = "status"              # æŒ‰çŠ¶æ€
    REVIEW_COUNT = "review_count"  # æŒ‰å¤ä¹ æ¬¡æ•°


@dataclass
class Note:
    """ç¬”è®°æ•°æ®ç»“æ„"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    content: str = ""
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    tags: List[str] = field(default_factory=list)
    
    def get_simplified_display(self, max_length: int = 50) -> str:
        """è·å–ç®€åŒ–æ˜¾ç¤ºç‰ˆæœ¬"""
        if len(self.content) <= max_length:
            return self.content
        return self.content[:max_length-3] + "..."
    
    def get_full_display(self, include_metadata: bool = True) -> str:
        """è·å–å®Œæ•´æ˜¾ç¤ºç‰ˆæœ¬"""
        if not include_metadata:
            return self.content
        
        created_time = datetime.fromisoformat(self.created_at)
        date_str = created_time.strftime("%Y-%m-%d %H:%M")
        result = f"[{date_str}] {self.content}"
        
        if self.tags:
            result += f" #{' #'.join(self.tags)}"
        
        return result


@dataclass
class CoreInfo:
    """æ ¸å¿ƒå•è¯ä¿¡æ¯"""
    pronunciation: str = ""
    primary_definition: str = ""
    part_of_speech: str = ""


@dataclass
class ExtendedInfo:
    """æ‰©å±•å•è¯ä¿¡æ¯"""
    definitions: List[str] = field(default_factory=list)
    examples: List[str] = field(default_factory=list)
    synonyms: List[str] = field(default_factory=list)
    antonyms: List[str] = field(default_factory=list)
    etymology: str = ""
    memory_tips: str = ""


@dataclass
class LearningData:
    """å­¦ä¹ æ•°æ®"""
    added_date: str = field(default_factory=lambda: datetime.now().isoformat())
    source: str = "manual_input"
    context: str = ""
    last_reviewed: str = ""
    next_review: str = ""
    review_count: int = 0
    correct_count: int = 0
    difficulty: DifficultyLevel = DifficultyLevel.MEDIUM


@dataclass
class AddWordConfig:
    """æ·»åŠ å•è¯æ—¶çš„é…ç½®"""
    skip_pronunciation: bool = False  # è·³è¿‡å‘éŸ³è¾“å…¥
    skip_part_of_speech: bool = False  # è·³è¿‡è¯æ€§è¾“å…¥
    skip_context: bool = False  # è·³è¿‡è¯­å¢ƒè¾“å…¥
    skip_tags: bool = False  # è·³è¿‡æ ‡ç­¾è¾“å…¥
    auto_promote_to_learning: bool = True  # æœ‰å®šä¹‰æ—¶è‡ªåŠ¨æå‡ä¸ºlearningçŠ¶æ€
    default_tags: List[str] = field(default_factory=list)  # é»˜è®¤æ ‡ç­¾


@dataclass
class UIChoiceDefaults:
    """UIé€‰æ‹©é¡¹çš„é»˜è®¤å€¼é…ç½®"""
    # ä¸»èœå•é»˜è®¤é€‰æ‹©
    main_menu_default: str = "1"
    
    # å¤ä¹ æ—¶çš„é»˜è®¤è¡¨ç°è¯„çº§
    review_performance_default: str = "g"  # good
    
    # è¯æ±‡è¡¨ç®¡ç†é»˜è®¤æ’åº
    vocabulary_sort_default: str = "1"  # æŒ‰å­—æ¯é¡ºåº
    
    # æ‰¹é‡æ“ä½œé»˜è®¤é€‰æ‹©
    batch_edit_default: str = "1"  # æ·»åŠ æ ‡ç­¾
    batch_status_default: str = "2"  # å­¦ä¹ ä¸­
    batch_difficulty_default: str = "2"  # ä¸­ç­‰
    
    # ç¬”è®°ç±»å‹é»˜è®¤é€‰æ‹©
    note_type_default: str = "5"  # è‡ªå®šä¹‰
    
    # ç¡®è®¤æ“ä½œé»˜è®¤å€¼
    confirm_continue_review: bool = True
    confirm_add_note: bool = False
    confirm_batch_edit: bool = False
    confirm_delete: bool = False


@dataclass
class AppConfig:
    """åº”ç”¨é…ç½®"""
    # è‡ªåŠ¨ä¿å­˜è®¾ç½®
    auto_save: bool = True
    auto_save_interval: int = 300  # ç§’
    
    # æ•°æ®æ–‡ä»¶è®¾ç½®
    data_file: str = "vocabulary.json"
    backup_enabled: bool = True
    backup_count: int = 5
    
    # å­¦ä¹ ç®—æ³•è®¾ç½®
    mastery_threshold: float = 0.8
    mastery_review_count: int = 3
    max_interval_days: int = 30
    
    # æ˜¾ç¤ºè®¾ç½®
    note_simplified_length: int = 50
    search_result_limit: int = 20
    
    # é—´éš”é‡å¤è®¾ç½®
    sr_base_intervals: Dict[str, float] = field(default_factory=lambda: {
        "excellent": 7.0,
        "good": 3.0,
        "fair": 1.0,
        "poor": 0.5
    })
    
    # æ·»åŠ å•è¯é…ç½®
    add_word_config: AddWordConfig = field(default_factory=AddWordConfig)
    
    # UIé€‰æ‹©é»˜è®¤å€¼é…ç½®
    ui_defaults: UIChoiceDefaults = field(default_factory=UIChoiceDefaults)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        result = asdict(self)
        # å¤„ç†åµŒå¥—çš„æšä¸¾æˆ–ç‰¹æ®Šç±»å‹
        return result
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'AppConfig':
        """ä»å­—å…¸åˆ›å»ºé…ç½®"""
        # å¤„ç†åµŒå¥—é…ç½®çš„è½¬æ¢
        if 'add_word_config' in data and isinstance(data['add_word_config'], dict):
            data['add_word_config'] = AddWordConfig(**data['add_word_config'])
        
        if 'ui_defaults' in data and isinstance(data['ui_defaults'], dict):
            data['ui_defaults'] = UIChoiceDefaults(**data['ui_defaults'])
        
        return cls(**data)
    
    def save(self, config_file: str = "config.json"):
        """ä¿å­˜é…ç½®"""
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    @classmethod
    def load(cls, config_file: str = "config.json") -> 'AppConfig':
        """åŠ è½½é…ç½®"""
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return cls.from_dict(data)
            except Exception as e:
                print(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
        return cls()  # è¿”å›é»˜è®¤é…ç½®


@dataclass
class Word:
    """å•è¯æ•°æ®ç»“æ„"""
    id: str
    word: str
    status: WordStatus = WordStatus.DRAFT
    completeness: float = 0.0
    tags: List[str] = field(default_factory=list)
    notes: List[Note] = field(default_factory=list)
    core_info: CoreInfo = field(default_factory=CoreInfo)
    extended_info: ExtendedInfo = field(default_factory=ExtendedInfo)
    learning_data: LearningData = field(default_factory=LearningData)
    
    def add_note(self, content: str, tags: List[str] = None) -> Note:
        """æ·»åŠ ç¬”è®°"""
        note = Note(content=content, tags=tags or [])
        self.notes.append(note)
        return note
    
    def get_notes_display(self, simplified: bool = True, 
                         include_metadata: bool = False) -> List[str]:
        """è·å–ç¬”è®°æ˜¾ç¤ºåˆ—è¡¨"""
        if not self.notes:
            return []
        
        if simplified:
            return [note.get_simplified_display() for note in self.notes]
        else:
            return [note.get_full_display(include_metadata) for note in self.notes]
    
    def calculate_completeness(self) -> float:
        """è®¡ç®—ä¿¡æ¯å®Œæ•´åº¦"""
        score = 0
        total = 10  # è°ƒæ•´æ€»åˆ†ä»¥åŒ…å«ç¬”è®°
        
        # æ ¸å¿ƒä¿¡æ¯æƒé‡æ›´é«˜
        if self.core_info.pronunciation: score += 1.5
        if self.core_info.primary_definition: score += 2
        if self.core_info.part_of_speech: score += 1
        
        # æ‰©å±•ä¿¡æ¯
        if self.extended_info.definitions: score += 1.5
        if self.extended_info.examples: score += 1.5
        if self.extended_info.synonyms: score += 1
        if self.extended_info.etymology: score += 0.5
        if self.extended_info.memory_tips: score += 0.5
        
        # ç¬”è®°åŠ åˆ†
        if self.notes: score += 0.5
        
        self.completeness = min(score / total, 1.0)
        return self.completeness
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'id': self.id,
            'word': self.word,
            'status': self.status.value,
            'completeness': self.completeness,
            'tags': self.tags,
            'notes': [asdict(note) for note in self.notes],
            'core_info': asdict(self.core_info),
            'extended_info': asdict(self.extended_info),
            'learning_data': enum_asdict(asdict(self.learning_data))
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Word':
        """ä»å­—å…¸åˆ›å»ºWordå¯¹è±¡"""
        word = cls(
            id=data['id'],
            word=data['word'],
            status=WordStatus(data.get('status', 'draft')),
            completeness=data.get('completeness', 0.0),
            tags=data.get('tags', [])
        )
        
        # é‡å»ºç¬”è®°
        if 'notes' in data:
            word.notes = [Note(**note_data) for note_data in data['notes']]
        
        # é‡å»ºå…¶ä»–ä¿¡æ¯
        if 'core_info' in data:
            word.core_info = CoreInfo(**data['core_info'])
        
        if 'extended_info' in data:
            word.extended_info = ExtendedInfo(**data['extended_info'])
        
        if 'learning_data' in data:
            ld_data = data['learning_data'].copy()
            if 'difficulty' in ld_data:
                if isinstance(ld_data['difficulty'], (str, int)):
                    ld_data['difficulty'] = DifficultyLevel(int(ld_data['difficulty']))
            word.learning_data = LearningData(**ld_data)
        
        return word


# æŠ½è±¡æ¥å£å®šä¹‰
class IVocabularyStorage(ABC):
    """è¯æ±‡å­˜å‚¨æ¥å£"""
    
    @abstractmethod
    def load(self) -> Dict[str, Word]:
        """åŠ è½½æ‰€æœ‰å•è¯"""
        pass
    
    @abstractmethod
    def save(self, words: Dict[str, Word]) -> bool:
        """ä¿å­˜æ‰€æœ‰å•è¯"""
        pass
    
    @abstractmethod
    def backup(self) -> bool:
        """å¤‡ä»½æ•°æ®"""
        pass


class ILearningAlgorithm(ABC):
    """å­¦ä¹ ç®—æ³•æ¥å£"""
    
    @abstractmethod
    def calculate_next_review(self, word: Word, performance: str) -> datetime:
        """è®¡ç®—ä¸‹æ¬¡å¤ä¹ æ—¶é—´"""
        pass
    
    @abstractmethod
    def should_promote_status(self, word: Word) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æå‡çŠ¶æ€"""
        pass


class IUIAdapter(Protocol):
    """UIé€‚é…å™¨æ¥å£"""
    
    def display_message(self, message: str, level: str = "info") -> None:
        """æ˜¾ç¤ºæ¶ˆæ¯"""
        ...
    
    def get_user_input(self, prompt: str, input_type: str = "text") -> Any:
        """è·å–ç”¨æˆ·è¾“å…¥"""
        ...
    
    def display_word_list(self, words: List[Word], simplified: bool = True) -> None:
        """æ˜¾ç¤ºå•è¯åˆ—è¡¨"""
        ...
    
    def display_statistics(self, stats: Dict[str, Any]) -> None:
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        ...


# å…·ä½“å®ç°ç±»
class JSONStorage(IVocabularyStorage):
    """JSONæ–‡ä»¶å­˜å‚¨å®ç°"""
    
    def __init__(self, config: AppConfig):
        self.config = config
    
    def load(self) -> Dict[str, Word]:
        """åŠ è½½æ•°æ®"""
        words = {}
        if os.path.exists(self.config.data_file):
            try:
                with open(self.config.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for word_data in data.get('words', []):
                        word = Word.from_dict(word_data)
                        words[word.id] = word
            except Exception as e:
                print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return words
    
    def save(self, words: Dict[str, Word]) -> bool:
        """ä¿å­˜æ•°æ®"""
        try:
            data = {
                'version': '1.1',
                'created_at': datetime.now().isoformat(),
                'word_count': len(words),
                'words': [word.to_dict() for word in words.values()]
            }
            with open(self.config.data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False
    
    def backup(self) -> bool:
        """åˆ›å»ºå¤‡ä»½"""
        if not self.config.backup_enabled or not os.path.exists(self.config.data_file):
            return False
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"{self.config.data_file}.backup.{timestamp}"
            
            import shutil
            shutil.copy2(self.config.data_file, backup_file)
            
            # æ¸…ç†æ—§å¤‡ä»½
            self._cleanup_old_backups()
            return True
        except Exception as e:
            print(f"å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def _cleanup_old_backups(self):
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
        try:
            import glob
            backup_pattern = f"{self.config.data_file}.backup.*"
            backup_files = sorted(glob.glob(backup_pattern), reverse=True)
            
            if len(backup_files) > self.config.backup_count:
                for old_backup in backup_files[self.config.backup_count:]:
                    os.remove(old_backup)
        except Exception as e:
            print(f"æ¸…ç†å¤‡ä»½å¤±è´¥: {e}")


class SimpleSpacedRepetition(ILearningAlgorithm):
    """ç®€å•é—´éš”é‡å¤ç®—æ³•å®ç°"""
    
    def __init__(self, config: AppConfig):
        self.config = config
    
    def calculate_next_review(self, word: Word, performance: str) -> datetime:
        """è®¡ç®—ä¸‹æ¬¡å¤ä¹ æ—¶é—´"""
        base_interval = self.config.sr_base_intervals.get(performance, 1.0)
        
        # æ ¹æ®å¤ä¹ æ¬¡æ•°è°ƒæ•´é—´éš”
        review_multiplier = min(word.learning_data.review_count * 0.3 + 1, 3.0)
        
        # æ ¹æ®æ­£ç¡®ç‡è°ƒæ•´
        if word.learning_data.review_count > 0:
            accuracy = word.learning_data.correct_count / word.learning_data.review_count
            accuracy_multiplier = max(0.5, accuracy * 1.5)
        else:
            accuracy_multiplier = 1.0
        
        final_interval = min(
            base_interval * review_multiplier * accuracy_multiplier,
            self.config.max_interval_days
        )
        
        return datetime.now() + timedelta(days=final_interval)
    
    def should_promote_status(self, word: Word) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æå‡çŠ¶æ€"""
        if word.learning_data.review_count < self.config.mastery_review_count:
            return False
        
        accuracy = word.learning_data.correct_count / word.learning_data.review_count
        return accuracy >= self.config.mastery_threshold


class VocabularyCore:
    """è¯æ±‡ç®¡ç†æ ¸å¿ƒç±»"""
    
    def __init__(self, config: AppConfig = None, 
                 storage: IVocabularyStorage = None,
                 algorithm: ILearningAlgorithm = None):
        self.config = config or AppConfig()
        self.storage = storage or JSONStorage(self.config)
        self.algorithm = algorithm or SimpleSpacedRepetition(self.config)
        
        self.words: Dict[str, Word] = {}
        self._auto_save_timer: Optional[threading.Timer] = None
        self._data_changed = False
        
        # äº‹ä»¶å›è°ƒ
        self.on_word_added: Optional[Callable[[Word], None]] = None
        self.on_word_updated: Optional[Callable[[Word], None]] = None
        self.on_data_saved: Optional[Callable[[], None]] = None
        
        self.load_data()
        if self.config.auto_save:
            self._start_auto_save()
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        self.words = self.storage.load()
        self._data_changed = False
    
    def save_data(self, force: bool = False) -> bool:
        """ä¿å­˜æ•°æ®"""
        if not force and not self._data_changed:
            return True
        
        success = self.storage.save(self.words)
        if success:
            self._data_changed = False
            if self.on_data_saved:
                self.on_data_saved()
        return success
    
    def add_word(self, word_str: str, **kwargs) -> Word:
        """æ·»åŠ æ–°å•è¯"""
        word_id = str(uuid.uuid4())
        word = Word(id=word_id, word=word_str.lower().strip())
        
        # è®¾ç½®å¯é€‰å‚æ•°
        for key, value in kwargs.items():
            if hasattr(word.core_info, key):
                setattr(word.core_info, key, value)
            elif hasattr(word.learning_data, key):
                setattr(word.learning_data, key, value)
            elif hasattr(word, key):
                setattr(word, key, value)
        
        # å¦‚æœæœ‰åŸºæœ¬å®šä¹‰ï¼ŒçŠ¶æ€æ”¹ä¸ºlearning
        if word.core_info.primary_definition:
            word.status = WordStatus.LEARNING
        
        word.calculate_completeness()
        self.words[word_id] = word
        self._data_changed = True
        
        if self.on_word_added:
            self.on_word_added(word)
        
        return word
    
    def update_word(self, word_id: str, **kwargs) -> Optional[Word]:
        """æ›´æ–°å•è¯"""
        word = self.words.get(word_id)
        if not word:
            return None
        
        for key, value in kwargs.items():
            if hasattr(word.core_info, key):
                setattr(word.core_info, key, value)
            elif hasattr(word.extended_info, key):
                setattr(word.extended_info, key, value)
            elif hasattr(word.learning_data, key):
                setattr(word.learning_data, key, value)
            elif hasattr(word, key):
                setattr(word, key, value)
        
        word.calculate_completeness()
        self._data_changed = True
        
        if self.on_word_updated:
            self.on_word_updated(word)
        
        return word
    
    def add_note_to_word(self, word_id: str, content: str, 
                        tags: List[str] = None) -> Optional[Note]:
        """ä¸ºå•è¯æ·»åŠ ç¬”è®°"""
        word = self.words.get(word_id)
        if not word:
            return None
        
        note = word.add_note(content, tags)
        word.calculate_completeness()
        self._data_changed = True
        
        if self.on_word_updated:
            self.on_word_updated(word)
        
        return note
    
    def get_word(self, word_id: str) -> Optional[Word]:
        """è·å–å•è¯"""
        return self.words.get(word_id)
    
    def search_words(self, query: str, limit: int = None) -> List[Word]:
        """æœç´¢å•è¯"""
        if not query:
            return []
        
        query = query.lower()
        results = []
        
        for word in self.words.values():
            if (query in word.word.lower() or 
                query in word.core_info.primary_definition.lower() or
                any(query in tag.lower() for tag in word.tags) or
                any(query in note.content.lower() for note in word.notes)):
                results.append(word)
        
        # æŒ‰ç›¸å…³åº¦æ’åºï¼ˆç®€å•å®ç°ï¼‰
        results.sort(key=lambda w: (
            query == w.word.lower(),  # ç²¾ç¡®åŒ¹é…ä¼˜å…ˆ
            query in w.word.lower(),  # å•è¯åŒ¹é…
            w.completeness  # å®Œæ•´åº¦é«˜çš„ä¼˜å…ˆ
        ), reverse=True)
        
        limit = limit or self.config.search_result_limit
        return results[:limit]
    
    def get_words_by_status(self, status: WordStatus) -> List[Word]:
        """æŒ‰çŠ¶æ€è·å–å•è¯"""
        return [w for w in self.words.values() if w.status == status]
    
    def get_words_for_review(self) -> List[Word]:
        """è·å–éœ€è¦å¤ä¹ çš„å•è¯"""
        now = datetime.now()
        review_words = []
        
        for word in self.words.values():
            if word.status in [WordStatus.LEARNING, WordStatus.REVIEWING]:
                if not word.learning_data.next_review:
                    review_words.append(word)
                else:
                    try:
                        next_review = datetime.fromisoformat(word.learning_data.next_review)
                        if now >= next_review:
                            review_words.append(word)
                    except:
                        review_words.append(word)
        
        return review_words
    
    def update_word_after_review(self, word_id: str, performance: str) -> bool:
        """å¤ä¹ åæ›´æ–°å•è¯çŠ¶æ€"""
        word = self.words.get(word_id)
        if not word:
            return False
        
        # æ›´æ–°å­¦ä¹ æ•°æ®
        word.learning_data.review_count += 1
        word.learning_data.last_reviewed = datetime.now().isoformat()
        
        if performance in ['excellent', 'good']:
            word.learning_data.correct_count += 1
        
        # è®¡ç®—ä¸‹æ¬¡å¤ä¹ æ—¶é—´
        next_review = self.algorithm.calculate_next_review(word, performance)
        word.learning_data.next_review = next_review.isoformat()
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æå‡çŠ¶æ€
        if self.algorithm.should_promote_status(word):
            if word.status == WordStatus.LEARNING:
                word.status = WordStatus.REVIEWING
            elif word.status == WordStatus.REVIEWING:
                word.status = WordStatus.MASTERED
        
        self._data_changed = True
        
        if self.on_word_updated:
            self.on_word_updated(word)
        
        return True
    
    def get_all_words_paginated(self, page: int = 1, page_size: int = 20, 
                               sort_by: SortOrder = SortOrder.ALPHABETICAL,
                               reverse: bool = False) -> Tuple[List[Word], int, int]:
        """è·å–åˆ†é¡µçš„å•è¯åˆ—è¡¨
        
        Args:
            page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
            page_size: æ¯é¡µå¤§å°
            sort_by: æ’åºæ–¹å¼
            reverse: æ˜¯å¦é€†åº
            
        Returns:
            (å•è¯åˆ—è¡¨, æ€»é¡µæ•°, æ€»æ•°é‡)
        """
        words_list = list(self.words.values())
        
        # æ’åº
        if sort_by == SortOrder.ALPHABETICAL:
            words_list.sort(key=lambda w: w.word.lower(), reverse=reverse)
        elif sort_by == SortOrder.ADDED_TIME:
            words_list.sort(key=lambda w: w.learning_data.added_date, reverse=reverse)
        elif sort_by == SortOrder.REVIEW_TIME:
            words_list.sort(key=lambda w: w.learning_data.last_reviewed or "1970-01-01", reverse=reverse)
        elif sort_by == SortOrder.COMPLETENESS:
            words_list.sort(key=lambda w: w.completeness, reverse=reverse)
        elif sort_by == SortOrder.STATUS:
            words_list.sort(key=lambda w: w.status.value, reverse=reverse)
        elif sort_by == SortOrder.REVIEW_COUNT:
            words_list.sort(key=lambda w: w.learning_data.review_count, reverse=reverse)
        
        # åˆ†é¡µ
        total_count = len(words_list)
        total_pages = (total_count + page_size - 1) // page_size
        
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        
        return words_list[start_idx:end_idx], total_pages, total_count
    
    def delete_word(self, word_id: str) -> bool:
        """åˆ é™¤å•è¯"""
        if word_id not in self.words:
            return False
        
        del self.words[word_id]
        self._data_changed = True
        return True
    
    def delete_words_batch(self, word_ids: List[str]) -> Tuple[int, int]:
        """æ‰¹é‡åˆ é™¤å•è¯
        
        Returns:
            (æˆåŠŸåˆ é™¤æ•°é‡, å¤±è´¥æ•°é‡)
        """
        success_count = 0
        fail_count = 0
        
        for word_id in word_ids:
            if self.delete_word(word_id):
                success_count += 1
            else:
                fail_count += 1
        
        return success_count, fail_count
    
    def update_word_comprehensive(self, word_id: str, **kwargs) -> Optional[Word]:
        """å…¨é¢æ›´æ–°å•è¯ä¿¡æ¯"""
        word = self.words.get(word_id)
        if not word:
            return None
        
        # æ›´æ–°æ ¸å¿ƒä¿¡æ¯
        if 'core_info' in kwargs:
            core_data = kwargs['core_info']
            for key, value in core_data.items():
                if hasattr(word.core_info, key):
                    setattr(word.core_info, key, value)
        
        # æ›´æ–°æ‰©å±•ä¿¡æ¯
        if 'extended_info' in kwargs:
            ext_data = kwargs['extended_info']
            for key, value in ext_data.items():
                if hasattr(word.extended_info, key):
                    setattr(word.extended_info, key, value)
        
        # æ›´æ–°å­¦ä¹ æ•°æ®
        if 'learning_data' in kwargs:
            learn_data = kwargs['learning_data']
            for key, value in learn_data.items():
                if hasattr(word.learning_data, key):
                    setattr(word.learning_data, key, value)
        
        # æ›´æ–°å…¶ä»–å±æ€§
        for key, value in kwargs.items():
            if key not in ['core_info', 'extended_info', 'learning_data']:
                if hasattr(word, key):
                    setattr(word, key, value)
        
        word.calculate_completeness()
        self._data_changed = True
        
        if self.on_word_updated:
            self.on_word_updated(word)
        
        return word
    
    def add_note_quick(self, word_id: str, content: str, 
                      tags: List[str] = None, context: str = "") -> Optional[Note]:
        """å¿«é€Ÿæ·»åŠ ç¬”è®°ï¼ˆæ”¯æŒæ›´å¤šåœºæ™¯ï¼‰"""
        word = self.words.get(word_id)
        if not word:
            return None
        
        # åˆ›å»ºå¸¦ä¸Šä¸‹æ–‡çš„ç¬”è®°
        note_content = content
        if context:
            note_content = f"[{context}] {content}"
        
        note = word.add_note(note_content, tags)
        word.calculate_completeness()
        self._data_changed = True
        
        if self.on_word_updated:
            self.on_word_updated(word)
        
        return note
    
    def add_note_during_review(self, word_id: str, content: str, 
                              review_context: str = "å¤ä¹ ä¸­") -> Optional[Note]:
        """å¤ä¹ æ—¶æ·»åŠ ç¬”è®°"""
        return self.add_note_quick(word_id, content, 
                                 tags=["review", "learning"], 
                                 context=review_context)
    
    def get_words_by_tag(self, tag: str) -> List[Word]:
        """æŒ‰æ ‡ç­¾è·å–å•è¯"""
        return [w for w in self.words.values() if tag in w.tags]
    
    def get_all_tags(self) -> List[str]:
        """è·å–æ‰€æœ‰æ ‡ç­¾"""
        all_tags = set()
        for word in self.words.values():
            all_tags.update(word.tags)
        return sorted(list(all_tags))
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡"""
        stats = {
            'total_words': len(self.words),
            'by_status': {},
            'avg_completeness': 0,
            'words_for_review': len(self.get_words_for_review()),
            'notes_count': sum(len(w.notes) for w in self.words.values()),
            'last_added': None,
            'last_reviewed': None,
            'total_tags': len(self.get_all_tags())
        }
        
        # çŠ¶æ€ç»Ÿè®¡
        for status in WordStatus:
            count = len(self.get_words_by_status(status))
            stats['by_status'][status.value] = count
        
        # å¹³å‡å®Œæ•´åº¦
        if self.words:
            total_completeness = sum(w.completeness for w in self.words.values())
            stats['avg_completeness'] = total_completeness / len(self.words)
        
        # æœ€è¿‘æ·»åŠ å’Œå¤ä¹ 
        words_list = list(self.words.values())
        if words_list:
            # æœ€è¿‘æ·»åŠ 
            latest_added = max(words_list, key=lambda w: w.learning_data.added_date)
            stats['last_added'] = latest_added.learning_data.added_date
            
            # æœ€è¿‘å¤ä¹ 
            reviewed_words = [w for w in words_list if w.learning_data.last_reviewed]
            if reviewed_words:
                latest_reviewed = max(reviewed_words, 
                                    key=lambda w: w.learning_data.last_reviewed)
                stats['last_reviewed'] = latest_reviewed.learning_data.last_reviewed
        
        return stats
    
    def _start_auto_save(self):
        """å¯åŠ¨è‡ªåŠ¨ä¿å­˜"""
        if self._auto_save_timer:
            self._auto_save_timer.cancel()
        
        def auto_save():
            if self._data_changed:
                self.save_data()
            self._start_auto_save()  # é‡æ–°è®¾ç½®å®šæ—¶å™¨
        
        self._auto_save_timer = threading.Timer(
            self.config.auto_save_interval, auto_save
        )
        self._auto_save_timer.daemon = True
        self._auto_save_timer.start()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._auto_save_timer:
            self._auto_save_timer.cancel()
        
        # ä¿å­˜æœªä¿å­˜çš„æ•°æ®
        if self._data_changed:
            self.save_data()


def create_default_core() -> VocabularyCore:
    """åˆ›å»ºé»˜è®¤é…ç½®çš„æ ¸å¿ƒå®ä¾‹"""
    config = AppConfig.load()
    return VocabularyCore(config)





if __name__ == "__main__":
    # æ¼”ç¤ºç”¨çš„ç®€å•æ§åˆ¶å°UIé€‚é…å™¨
    class ConsoleUI:
        """ç®€å•çš„æ§åˆ¶å°UIå®ç°"""
        
        def display_message(self, message: str, level: str = "info"):
            prefix = {"info": "â„¹", "success": "âœ“", "warning": "âš ", "error": "âœ—"}
            print(f"{prefix.get(level, 'â„¹')} {message}")
        
        def get_user_input(self, prompt: str, input_type: str = "text") -> Any:
            if input_type == "text":
                return input(f"{prompt}: ").strip()
            elif input_type == "choice":
                return input(f"{prompt} (y/n): ").lower() == 'y'
            return input(f"{prompt}: ")
        
        def display_word_list(self, words: List[Word], simplified: bool = True):
            if not words:
                print("æ— å•è¯")
                return
            
            for i, word in enumerate(words, 1):
                status_icon = {"draft": "ğŸ“", "learning": "ğŸ“š", "reviewing": "ğŸ”„", "mastered": "âœ…"}
                print(f"{i}. {status_icon.get(word.status.value, '?')} {word.word}")
                print(f"   {word.core_info.primary_definition}")
                if word.notes and not simplified:
                    for note in word.notes[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªç¬”è®°
                        print(f"   ğŸ’¬ {note.get_simplified_display()}")
                print(f"   å®Œæ•´åº¦: {word.completeness:.1%} | çŠ¶æ€: {word.status.value}")
                print()
        
        def display_statistics(self, stats: Dict[str, Any]):
            print("=== å­¦ä¹ ç»Ÿè®¡ ===")
            print(f"æ€»å•è¯æ•°: {stats['total_words']}")
            print(f"å¹³å‡å®Œæ•´åº¦: {stats['avg_completeness']:.1%}")
            print(f"å¾…å¤ä¹ : {stats['words_for_review']}")
            print(f"ç¬”è®°æ€»æ•°: {stats['notes_count']}")
            print("\nçŠ¶æ€åˆ†å¸ƒ:")
            for status, count in stats['by_status'].items():
                print(f"  {status}: {count}")
    # ç®€å•æ¼”ç¤º
    print("=== å•è¯è®°å¿†ç¨‹åºæ ¸å¿ƒæ¨¡å—æ¼”ç¤º ===")
    
    core = create_default_core()
    ui = ConsoleUI()
    
    # æ¼”ç¤ºæ·»åŠ å•è¯
    word = core.add_word("ubiquitous", 
                        primary_definition="existing everywhere",
                        pronunciation="/juËËˆbÉªkwÉªtÉ™s/")
    
    # æ·»åŠ ç¬”è®°
    core.add_note_to_word(word.id, "åœ¨The Economistæ–‡ç« ä¸­é‡åˆ°", ["reading"])
    
    ui.display_message("å·²æ·»åŠ ç¤ºä¾‹å•è¯", "success")
    ui.display_word_list([word], simplified=False)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    stats = core.get_statistics()
    ui.display_statistics(stats)
    
    core.cleanup()